# End-to-End Testing with Playwright

Comprehensive E2E testing setup for validating request correlation and telemetry traceability across the entire application stack.

## Overview

This test suite demonstrates **end-to-end request traceability** by:

1. **Triggering a user action** in the web app
2. **Capturing the request ID** generated by the UI
3. **Verifying API error handling** and response correlation
4. **Confirming telemetry emission** with the same request ID
5. **Validating the complete audit trail** from UI to API to telemetry

## Test Architecture

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Web App   │    │  API Server │    │ Telemetry   │
│  (port 5173)│───▶│ (port 3000) │───▶│  Endpoint   │
└─────────────┘    └─────────────┘    └─────────────┘
       │                   │                   │
       ▼                   ▼                   ▼
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Request   │    │   Request   │    │   Request   │
│     ID      │    │Correlation  │    │     ID      │
│ Generation  │    │ Middleware  │    │ Validation  │
└─────────────┘    └─────────────┘    └─────────────┘
```

## Configuration

### Environment Variables

- **`USE_DEV_SERVER=1`** - Use Vite dev server (fast, no build required)
- **`CI`** - Enables CI-specific settings (retries, workers, etc.)

### Test Modes

#### Development Mode (Fast)
```bash
USE_DEV_SERVER=1 pnpm test
```
- Uses Vite dev server with hot reload
- No build step required
- Optimal for rapid development and debugging
- Proxies API calls through Vite's built-in proxy

#### Production Mode (Realistic)
```bash
pnpm test
```
- Builds the web app first (via `pretest` script)
- Uses Vite preview server with built assets
- Simulates production-like deployment
- More accurate performance characteristics

### Playwright Configuration

Located in `playwright.config.ts`:

```typescript
export default defineConfig({
  testDir: 'tests',                    // Test files location
  fullyParallel: true,                 // Run tests in parallel (overridden by serial config)
  forbidOnly: !!process.env.CI,       // Prevent .only() in CI
  retries: process.env.CI ? 2 : 0,     // Retry failed tests in CI
  workers: process.env.CI ? 1 : undefined, // Single worker in CI
  reporter: [['html', { outputFolder: 'playwright-report' }]],
  
  use: {
    baseURL: 'http://localhost:5173',  // Web app URL
    trace: 'on-first-retry',           // Capture traces on retry
    screenshot: 'only-on-failure',     // Screenshots on failure
    video: 'retain-on-failure',       // Videos on failure
  },
  
  projects: [
    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },
  ],
  
  webServer: {
    // Automatically starts web server based on USE_DEV_SERVER
    command: useDevServer 
      ? 'cd ../../apps/web && pnpm dev --port 5173 --strictPort'
      : 'cd ../../apps/web && pnpm preview --port 5173 --strictPort',
    url: 'http://localhost:5173',
    reuseExistingServer: !process.env.CI,
    timeout: 90_000,
  },
});
```

**Note:** Tests in `traceability.spec.ts` are configured to run serially (`test.describe.configure({ mode: 'serial' })`) to avoid conflicts with the shared debug endpoints.

## Test Scenarios

### Test 1: End-to-End Request Traceability

**File:** `tests/traceability.spec.ts`

**Objective:** Verify complete request correlation from UI action to telemetry logging

**Test Flow:**
1. **Navigate** to the web application
2. **Verify** page loads correctly  
3. **Click** "Trigger API Error" button (real user interaction)
4. **Wait** for network requests to complete
5. **Extract** request ID from `window.__lastReqId`
6. **Fetch** last telemetry event from debug endpoint
7. **Assert** request IDs match between UI and telemetry

**What This Tests:**
- Real UI interaction triggers telemetry
- Request correlation flows end-to-end
- Web app's fetch wrapper works correctly
- Navigator.sendBeacon/fetch fallback behavior
- API properly stores telemetry events

**Code Example:**
```typescript
test('end-to-end request traceability with telemetry correlation', async ({ page }) => {
  // Navigate and verify page load
  await page.goto('/');
  await expect(page.locator('h1')).toContainText('QA Instrumentation Demo');
  
  // Trigger API error via real UI interaction
  const button = page.locator('button:has-text("Trigger API Error")');
  await button.click();
  await page.waitForTimeout(1000);
  
  // Capture request ID from window
  const requestId = await page.evaluate(() => (window as any).__lastReqId);
  expect(requestId).toMatch(/^[0-9a-f-]+$/i);
  
  // Verify telemetry correlation
  const response = await page.request.get('http://localhost:3000/debug/last-event');
  expect(response.status()).toBe(200);
  
  const lastEvent = await response.json();
  expect(lastEvent).toMatchObject({
    level: 'error',
    env: 'development', 
    release: 'local',
    route: '/api/fail',
    status: 500,
    error_code: 'HTTP_ERROR',
    request_id: requestId,
  });
});
```

### Test 2: API Security and Data Scrubbing Contract

**File:** `tests/traceability.spec.ts`

**Objective:** Validate API's telemetry scrubbing and security contract compliance

**Test Flow:**
1. **Navigate** to establish context
2. **Send** telemetry event with realistic sensitive data to API
3. **Verify** API accepts and processes the event (204 response)
4. **Fetch** processed event from `/debug/telemetry/last`
5. **Assert** sensitive data was properly scrubbed
6. **Assert** normal data was preserved unchanged
7. **Verify** no raw sensitive data appears anywhere in response

**What This Tests:**
- API properly scrubs sensitive data in telemetry details
- Email addresses are redacted (***@domain format)
- Sensitive keys (password, apiKey, authToken) are redacted
- String truncation prevents log explosion
- Normal data is preserved (no over-scrubbing)
- Request correlation works for direct API calls
- API security contract is maintained

**Code Example:**
```typescript
test('API telemetry scrubbing and validation contract', async ({ page }) => {
  await page.goto('/');
  
  const testRequestId = 'scrub-contract-' + Date.now();
  
  // Send realistic sensitive data that could appear in error details
  const telemetryResponse = await page.request.post('http://localhost:3000/telemetry', {
    headers: { 'Content-Type': 'application/json', 'x-request-id': testRequestId },
    data: {
      ts: Date.now(),
      level: 'error',
      env: 'development',
      release: 'local',
      route: '/api/sensitive-operation',
      status: 400,
      error_code: 'VALIDATION_ERROR',
      details: {
        userEmail: 'user@company.com',          // Email in error context
        apiKey: 'sk-1234567890abcdef1234',      // Accidentally logged API key
        password: 'leaked-password',             // Password in form data
        normalField: 'safe-to-log',             // Non-sensitive data
        longTrace: 'x'.repeat(600)              // Long stack trace
      }
    }
  });
  
  expect(telemetryResponse.status()).toBe(204);
  
  // Verify scrubbing worked
  const debugResponse = await page.request.get('http://localhost:3000/debug/telemetry/last');
  const scrubbedEvent = await debugResponse.json();
  
  // Assert correlation
  expect(scrubbedEvent.request_id).toBe(testRequestId);
  
  // Assert sensitive data scrubbed
  expect(scrubbedEvent.details.userEmail).toBe('***@company.com');
  expect(scrubbedEvent.details.apiKey).toBe('[REDACTED]');
  expect(scrubbedEvent.details.password).toBe('[REDACTED]');
  
  // Assert normal data preserved
  expect(scrubbedEvent.details.normalField).toBe('safe-to-log');
  
  // Assert string truncation
  expect(scrubbedEvent.details.longTrace).toHaveLength(500);
  
  // Assert no leakage - negative testing
  const eventString = JSON.stringify(scrubbedEvent);
  expect(eventString).not.toContain('user@company.com');
  expect(eventString).not.toContain('leaked-password');
});
```

### Test Artifacts

#### On Test Failure
- **Screenshot** - Visual state when test failed
- **Video** - Recording of the entire test execution  
- **Trace** - Detailed timeline with network requests, DOM changes, and console logs
- **Error Context** - Additional debugging information

#### Artifact Locations
```
tests/e2e/
├── playwright-report/        # HTML report with embedded artifacts
├── test-results/            # Raw test artifacts
│   └── [test-name]-[browser]/
│       ├── test-failed-1.png
│       ├── video.webm
│       └── trace.zip
└── tests/
    └── traceability.spec.ts
```

## Running Tests

### Prerequisites

```bash
# Ensure all dependencies are installed
pnpm install

# Build the telemetry package
pnpm -C packages/telemetry build

# Install Playwright browsers (if not already done)
pnpm exec playwright install --with-deps
```

### Basic Commands

```bash
# Run all tests (production mode)
pnpm test

# Run tests in development mode (faster)
USE_DEV_SERVER=1 pnpm test

# Run with UI mode for debugging
pnpm test:ui

# View test report
pnpm report
```

### Advanced Usage

```bash
# Run specific test file
pnpm exec playwright test traceability.spec.ts

# Run with debug mode
pnpm exec playwright test --debug

# Run headed (visible browser)
pnpm exec playwright test --headed

# Generate traces for all tests
pnpm exec playwright test --trace on
```

### With Manual Server Setup

If you prefer to start servers manually:

```bash
# Terminal 1: Start API server
cd apps/api && pnpm dev

# Terminal 2: Start web server  
cd apps/web && pnpm dev

# Terminal 3: Run tests (skip auto server start)
cd tests/e2e
USE_DEV_SERVER=1 pnpm exec playwright test
```

## Debugging Tests

### Common Issues

#### Port Conflicts
```bash
# Check for processes using required ports
lsof -ti:3000  # API server
lsof -ti:5173  # Web server

# Kill conflicting processes
lsof -ti:3000 | xargs kill -9
lsof -ti:5173 | xargs kill -9
```

#### Server Not Starting
```bash
# Check server logs
tail -f apps/api/logs/server.log
tail -f apps/web/logs/vite.log

# Verify dependencies
pnpm -C apps/api install
pnpm -C apps/web install
```

#### Test Failures
```bash
# Run with verbose output
DEBUG=pw:* pnpm test

# Capture traces for debugging
pnpm exec playwright test --trace on

# Run in headed mode to watch execution
pnpm exec playwright test --headed --slowMo=1000
```

### Visual Debugging

#### Test Trace Analysis
1. Open `playwright-report/index.html` in browser
2. Click on failed test
3. View embedded trace with timeline
4. Inspect network requests, console logs, and DOM changes

#### Screenshot Analysis
- Screenshots capture the exact visual state when tests fail
- Useful for identifying UI issues or unexpected states
- Automatically embedded in HTML reports

## CI/CD Integration

### GitHub Actions Example

```yaml
name: E2E Tests

on: [push, pull_request]

jobs:
  e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: 9
          
      - name: Install dependencies
        run: pnpm install
        
      - name: Build packages
        run: pnpm -r build
        
      - name: Install Playwright browsers
        run: pnpm -C tests/e2e exec playwright install --with-deps
        
      - name: Run E2E tests
        run: pnpm -C tests/e2e test
        
      - name: Upload Playwright report
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: tests/e2e/playwright-report/
          retention-days: 30
```

### CI Optimizations

- **Parallel execution** disabled in CI for reliability
- **Automatic retries** on failure (2x in CI)
- **Single worker** to avoid resource conflicts
- **Artifact collection** for debugging failed tests
- **Deterministic builds** with locked dependencies

## Test Development Guidelines

### Writing New Tests

1. **Follow the request correlation pattern** - Always verify request IDs
2. **Use proper wait strategies** - Avoid fixed timeouts where possible
3. **Test error scenarios** - Verify telemetry on failures
4. **Include assertions for telemetry schema** - Validate event structure
5. **Clean up after tests** - Reset state between test runs

### Best Practices

```typescript
// ✅ Good: Specific selectors and proper waits
await page.locator('[data-testid="trigger-error"]').click();
await page.waitForResponse(response => 
  response.url().includes('/api/fail') && response.status() === 500
);

// ❌ Bad: Generic selectors and fixed timeouts
await page.locator('button').click();
await page.waitForTimeout(2000);

// ✅ Good: Comprehensive telemetry validation
expect(telemetryEvent).toMatchObject({
  ts: expect.any(Number),
  level: 'error',
  request_id: expect.stringMatching(/^[0-9a-f-]+$/i),
  status: 500,
});

// ❌ Bad: Partial validation
expect(telemetryEvent.level).toBe('error');
```

### Request Correlation Testing

Every test involving user actions should verify request correlation:

```typescript
// 1. Trigger user action
await page.locator('[data-action="api-call"]').click();

// 2. Capture request ID
const requestId = await page.evaluate(() => window.__lastReqId);

// 3. Verify telemetry correlation
const telemetryResponse = await page.request.get('/debug/last-event');
const telemetryEvent = await telemetryResponse.json();
expect(telemetryEvent.request_id).toBe(requestId);
```

## Performance Considerations

### Test Speed Optimization

- **Use `USE_DEV_SERVER=1`** for faster test cycles during development
- **Limit browser instances** - Single browser sufficient for most tests  
- **Reuse server instances** - Let Playwright manage server lifecycle
- **Parallel execution** - Enable for large test suites (disabled in CI)

### Resource Management

- **Memory usage** - Each browser context uses ~50MB
- **Network overhead** - Tests make real HTTP requests
- **Disk space** - Artifacts can accumulate quickly
- **Port conflicts** - Ensure clean port usage with `strictPort: true`

## Monitoring and Metrics

### Test Metrics to Track

- **Test execution time** - Monitor for performance regressions
- **Failure rate** - Track test stability over time
- **Artifact size** - Monitor storage requirements
- **Coverage** - Ensure critical paths are tested

### Alerting

Set up alerts for:
- **Consistent test failures** - May indicate product issues
- **Slow test execution** - Performance degradation
- **High artifact storage** - Storage cost management
- **Missing telemetry events** - Instrumentation failures

The E2E test suite provides comprehensive validation of the request correlation and telemetry system, ensuring that the instrumentation works correctly end-to-end and produces actionable debugging information when issues occur.